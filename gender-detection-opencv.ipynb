{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44fd32-6e63-4ddc-855d-0d7b7e65eed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from IPython.core.display import display, HTML\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376dfe10-bc6c-4c3a-bb2a-f7c79493198c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "physical_devices = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "tensorflow.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1959c64-887f-45c8-9fac-b639353a92b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_folder = \"C:/Users/ahmet/Calismalarim/opencv\"\n",
    "image_folder = main_folder + \"/img_align_celeba/img_align_celeba/\"\n",
    "example_picture = \"C:/Users/ahmet/Calismalarim/opencv/img_align_celeba/img_align_celeba/000103.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac1d4e-8119-4b74-95b1-3d891d3086b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(main_folder + '/list_attr_celeba.csv')\n",
    "df = df_.copy()\n",
    "df.set_index('image_id', inplace=True)\n",
    "df.replace(to_replace=-1, value=0, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c413ff6-7f63-4f85-8867-580f86823415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, j in enumerate(df.columns):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66292de1-682b-423a-9be2-66868589c784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\"Male\": \"Gender\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdec5c8-6791-4bce-a421-61340cb903cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = load_img(example_picture)\n",
    "plt.grid(False)\n",
    "plt.imshow(img)\n",
    "\n",
    "df.loc[example_picture.split('/')[-1]][['Attractive','Gender','Young']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32007dc-6bdf-4ef2-b4cc-ee33fafacaad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(\"Female and Male\")\n",
    "sns.countplot(y=\"Gender\", data=df, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e1085-81ca-4331-bd7e-5756c76b1884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_part = pd.read_csv(main_folder + \"/list_eval_partition.csv\")\n",
    "df_part.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cdce9f-f42c-4ce5-9ca1-339b49da7edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_part.partition.value_counts()\n",
    "\n",
    "# 0 -> train\n",
    "# 1 -> validation\n",
    "# 2 -> test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc73607-bf71-4393-a77a-84d2372d6079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_part.set_index(\"image_id\", inplace=True)\n",
    "df_part = df_part.join(df.Gender, how='inner')\n",
    "df_part.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92735fb4-70a1-48ae-970f-c3fa0e199560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_width = 178\n",
    "img_height = 218\n",
    "\n",
    "def load_reshape_img(fname):\n",
    "    img = load_img(fname)\n",
    "    x = img_to_array(img)/255.\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def generate_df(partition, attr, num_samples):\n",
    "    \n",
    "    df_ = df_part[(df_part['partition'] == partition) \n",
    "                           & (df_part[attr] == 0)].sample(int(num_samples/2))\n",
    "    df_ = pd.concat([df_,\n",
    "                      df_part[(df_part['partition'] == partition) \n",
    "                                  & (df_part[attr] == 1)].sample(int(num_samples/2))])\n",
    "\n",
    "    if partition != 2:\n",
    "        x_ = np.array([load_reshape_img(image_folder + fname) for fname in df_.index])\n",
    "        x_ = x_.reshape(x_.shape[0], 218, 178, 3)\n",
    "        y_ = np_utils.to_categorical(df_[attr],2)\n",
    "    else:\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        for index, target in df_.iterrows():\n",
    "            im = cv2.imread(image_folder + index)\n",
    "            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (img_width, img_height)).astype(np.float32) / 255.0\n",
    "            im = np.expand_dims(im, axis =0)\n",
    "            x_.append(im)\n",
    "            y_.append(target[attr])\n",
    "\n",
    "    return x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709db3bc-a80e-43cf-88ad-3afc866e74a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,      \n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,       \n",
    "    zoom_range=0.2,      \n",
    "    horizontal_flip=True,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed791d-63ed-48b9-8c10-e314d2031a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = load_img(example_picture)\n",
    "x = img_to_array(img)/255.\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.suptitle('Data Augmentation', fontsize=28)\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.grid(False)\n",
    "    plt.imshow( batch.reshape(218, 178, 3))\n",
    "    \n",
    "    if i == 9:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b97af-14b8-47fb-8ee7-a3d0228f0dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_samples = 20000\n",
    "x_train, y_train = generate_df(0, 'Gender', training_samples)\n",
    "\n",
    "train_datagen =  ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input,\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    ")\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "x_train, y_train,\n",
    "batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ec8e8-e4cc-4a79-9102-0f910ad620a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_samples=4000\n",
    "x_valid, y_valid = generate_df(1, 'Gender', validation_samples)\n",
    "\n",
    "valid_datagen =  ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input,\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    ")\n",
    "\n",
    "valid_datagen.fit(x_valid)\n",
    "\n",
    "valid_generator = valid_datagen.flow(\n",
    "x_valid, y_valid,\n",
    "batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31a09e-711f-46f2-a412-3992b7b76512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inception_model = InceptionV3(weights='C:\\Users\\user\\inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', \n",
    "                              include_top=False, input_shape = (img_height, img_width, 3))\n",
    "\n",
    "print(\"number of layers:\", len(inception_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51c1fd-353f-472e-9a66-7abfc89b30e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = inception_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "custom_model = Model(inputs=inception_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152ab7c-0aaa-422e-8059-c5e2e06b8e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for layer in custom_model.layers[:52]:\n",
    "    layer.trainable = False\n",
    "\n",
    "custom_model.compile(optimizer=Adam(learning_rate=0.0005)\n",
    "                    , loss='categorical_crossentropy'\n",
    "                    , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabd933-6c42-4920-bcdb-6fafbd9fcf39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=1)\n",
    "\n",
    "hist = custom_model.fit(train_generator, validation_data=(x_valid, y_valid), \n",
    "                 steps_per_epoch=training_samples/32, epochs=20, verbose=1, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83417b-4265-4b60-b124-d6595fc97af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_training(history, lw = 3):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    \n",
    "visualize_training(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a89c9-4840-4171-bce6-71a06c2c0402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_samples = 4000\n",
    "x_test, y_test = generate_df(2, 'Gender', test_samples)\n",
    "model_predictions = [np.argmax(custom_model.predict(feature)) for feature in x_test ]\n",
    "\n",
    "test_accuracy = 100 * np.sum(np.array(model_predictions)==y_test) / len(model_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "print('f1_score:', f1_score(y_test, model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127c591-5787-4164-9dc2-e13963ed77af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gender_target = {0: 'Female'\n",
    "                , 1: 'Male'}\n",
    "\n",
    "def img_to_display(filename):\n",
    " \n",
    "    i = Image.open(filename)\n",
    "    i.thumbnail((200, 200), Image.LANCZOS)\n",
    "    \n",
    "    with BytesIO() as buffer:\n",
    "        i.save(buffer, 'jpeg')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "    \n",
    "\n",
    "def display_result(filename, prediction, target):\n",
    "    gender = 'Male'\n",
    "        \n",
    "    if prediction[1] <= 0.5:\n",
    "        gender = 'Female'\n",
    "            \n",
    "    display_html = '''\n",
    "    <div style=\"overflow: auto;  border: 2px solid #D8D8D8;\n",
    "        padding: 5px; width: 480px;\" >\n",
    "        <img src=\"data:image/jpeg;base64,{}\" style=\"float: left;\" width=\"200\" height=\"200\">\n",
    "        <div style=\"padding: 10px 0px 0px 20px; overflow: auto;\">\n",
    "            <h3 style=\"margin-left: 50px; margin-top: 2px;\">Prediction: {}</h3>\n",
    "            <p style=\"margin-left: 50px; margin-top: -6px; font-size: 12px\">{} probability</p>\n",
    "            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Real gender: {}</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    '''.format(img_to_display(filename)\n",
    "               , gender\n",
    "               , \"{0:.2f}%\".format(round(max(prediction)*100,2))\n",
    "               , gender_target[target]\n",
    "               , filename.split('/')[-1]\n",
    "               )\n",
    "\n",
    "    display(HTML(display_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c5ab0-0539-4476-ac47-0ad6dcd893a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gender_prediction(filename):\n",
    "    im = cv2.imread(filename)\n",
    "    im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) / 255.0\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    \n",
    "    result = custom_model.predict(im)\n",
    "    prediction = np.argmax(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "df_to_test = df_part[df_part['partition'] == 2].sample(3)\n",
    "\n",
    "for index, target in df_to_test.iterrows():\n",
    "    result = gender_prediction(image_folder + index)\n",
    "    display_result(image_folder + index, result[0], target['Gender'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28e8f1-3c9c-4b5e-a7e1-cb9d96c30eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
